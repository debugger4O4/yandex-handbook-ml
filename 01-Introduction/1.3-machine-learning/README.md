## Машинное обучение

### Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение

**Машинное обучение** — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту.

Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные
машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина
могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно
написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи),
которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. 
Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то 
крайне трудно запрограммировать, например:
- перевести текст с одного языка на другой;
- диагностировать болезнь по симптомам;
- сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос;
- сказать, что изображено на картинке;
- оценить, по какой цене удастся продать квартиру.

У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает **объекты** или 
**примеры** (samples) в **предсказания** (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности.
Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут 
по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. 
В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на 
картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или 
подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда 
сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — **моделью**, а имеющийся у нас набор 
примеров — **обучающей выборкой** или **датасетом**. Обучающая выборка состоит из:
- **объектов** (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее);
- и **ответов** (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда
называть **таргетами**.

### Постановка задач

Описанные выше задачи являются примерами задач **обучения с учителем (supervised learning)**, так как правильные ответы для 
каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости 
от того, каким может быть множество $Y$ всех возможных ответов (таргетов):
1. `Y = R` или `Y = R^M` — **регрессия**. Примерами задач регрессии является предсказание продолжительности
поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, 
влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания).
2. `Y = {0, 1}` — **бинарная классификация**. Например, мы можем предсказывать, кликнет ли пользователь по рекламному 
объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, есть ли на картинке банан.
3. `Y = {1, ..., K}` — **многоклассовая (multiclass) классификация**. Например, определение предметной области для научной
статьи (математика, биология, психология и т.д.).
4. `Y = {0, 1}^K` —** многоклассовая классификация с пересекающимися классами (multilabel classification)**. Например, 
задача автоматического простановки тегов для ресторанов (логично, что ресторан может одновременно иметь несколько тегов).
5. `Y` — конечное упорядоченное множество — **ранжирование**. Основным примером является задача ранжирования поисковой выдачи,
где для любого запроса нужно отсортировать все возможные документы по релевантности этому запросу; при этом оценка 
релевантности имеет смысл только в контексте сравнения двух документов между собой, её абсолютное значение информации 
не несёт.

Ответ может быть и более сложным. Так, в задаче сегментации изображения требуется для каждого пикселя предсказать, к 
какому объекту или типу объектов он относится, а в задаче машинного перевода мы должны сгенерировать предложение 
(или целый текст), являющееся переводом исходного. Интерес представляют и задачи порождения новых объектов, то есть 
генерации правдоподобных объектов, из ничего или на основе уже существующих. С помощью такой модели также можно научиться 
увеличивать разрешение изображения и применять любимые всеми маски в Snapchat или Instagram.

Есть и относительно небольшой класс задач, относящихся к обучению без учителя (unsupervised learning), — это задачи, 
для которых нам известны только данные, а ответы неизвестны или вообще не существуют. Более того, часто поиск "правильных"
ответов не является самоцелью. Классическим примером обучения без учителя является кластеризация — задача разделения 
объектов на группы, обладающие некоторыми неизвестными нам, но, как мы в глубине души надеемся, интерпретируемыми свойствами.
Примером может служить кластеризация документов из электронной библиотеки по темам или кластеризация новостей с целью 
выделения крупных сюжетов.

Бывают и другие виды (и даже парадигмы) машинного обучения, так что если вы встретите задачу, которую никак не получается
отнести к одному из перечисленных выше типов, не расстраивайтесь и знайте, что где-то дальше в учебнике вас ждёт рассказ
про такие задачи.

**Предсказание курса евро к доллару на следующий день.**</br>
Это задача регрессии. Модель предсказывает вещественное число, пусть и с небольшим количеством знаков после запятой.

**Стилизация текста. Например, перевод на бюрократический язык: «Пиппина и Мерри похитили!»
↦
↦ «Граждане Тук, Перегрин Паладинович, 2990 года рождения, и Брендибак, Мериадок Сарадокович, 2982 года рождения, 
были похищены неустановленными лицами».**</br>
Это задача генерации новых объектов на основе уже существующих.

**Детектирование котиков на изображении.**</br>
В зависимости от того, для чего мы детектируем котиков, это может быть задача регрессии (предсказание координат вершин 
прямоугольника, в котором находится котик) или классификации (если нас просто интересует, есть котик или нет).

**Обучение робокота запрыгивать на стол из произвольной позы.**</br>
Эту задачу можно решать по-разному. Например, создав физическую модель движения робокота и рассчитав оптимальную 
последовательность движений. Если мы всё-таки хотим решать её с помощью машинного обучения, то можно поступить следующим
образом. Создадим компьютерную симуляцию (чтобы не ломать настоящего робота) и модель, которая будет в каждый момент на
основе конфигурации сочленений, высоты от пола, расстояния до стола, фазы Луны и других важных параметров предсказывать,
как нужно дальше поворачивать лапы, изгибать спину кота и так далее. Эту модель будем прогонять в симуляции, так или 
иначе меняя её в зависимости от того, насколько удачно робот справляется со своей задачей. Такая парадигма называется 
**обучением с подкреплением (reinforcement learning)**.

**Поиск наборов товаров, которые посетители супермаркета часто покупают вместе.**</br>
Это задача обучения без учителя.

**Ранжирование — это задача с таргетом из конечного упорядоченного множества `(1, …,K)`. Казалось бы, её запросто можно 
было бы рассматривать как задачу классификации на `K` классов или задачу регрессии. В чём же проблема? Почему так не делают?**</br>
Для решения задач ранжирования обычно строят модель, предсказывающую некоторое вещественное число, по которому затем 
сортируют объекты, — так почему бы не считать её регрессией? Дело в том, что функции потерь и метрики в этой задаче совсем
другие. Нам неважно, какие именно вещественные числа мы предсказываем. Мы просто хотим, чтобы более релевантным объектам
сопоставлялись числа побольше.
Задача «предскажите 10 самых релевантных объектов» не похожа на задачу классификации. Мир меняется, появляются новые 
объекты, и если к нам в руки попадёт объект более релевантный, чем текущий топ-1, все номера позиций поедут, и выученное
нами соответствие объектов и номеров можно будет выкидывать на помойку.

### Критерии качества